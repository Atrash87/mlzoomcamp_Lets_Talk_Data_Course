{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae2cda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6148900d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    lead_source    industry  number_of_courses_viewed  annual_income  \\\n",
      "0      paid_ads         NaN                         1        79450.0   \n",
      "1  social_media      retail                         1        46992.0   \n",
      "2        events  healthcare                         5        78796.0   \n",
      "3      paid_ads      retail                         2        83843.0   \n",
      "4      referral   education                         3        85012.0   \n",
      "\n",
      "  employment_status       location  interaction_count  lead_score  converted  \n",
      "0        unemployed  south_america                  4        0.94          1  \n",
      "1          employed  south_america                  1        0.80          0  \n",
      "2        unemployed      australia                  3        0.69          1  \n",
      "3               NaN      australia                  1        0.87          0  \n",
      "4     self_employed         europe                  3        0.62          1  \n"
     ]
    }
   ],
   "source": [
    "# Getting data from a URL\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Optionally inspect\n",
    "print(df.head())\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel(\"course_lead_scoring.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c03cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(\"course_lead_scoring.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04318edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after filling:\n",
      "lead_source                 0\n",
      "industry                    0\n",
      "number_of_courses_viewed    0\n",
      "annual_income               0\n",
      "employment_status           0\n",
      "location                    0\n",
      "interaction_count           0\n",
      "lead_score                  0\n",
      "converted                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file\n",
    "df = pd.read_excel(\"course_lead_scoring.xlsx\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':  # Categorical features\n",
    "        df[col] = df[col].fillna('NA')\n",
    "    else:  # Numerical features\n",
    "        df[col] = df[col].fillna(0.0)\n",
    "\n",
    "# Verify that all missing values are handled\n",
    "print(\"\\nMissing values after filling:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90eca6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retail'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7100e500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The biggest correlation is between converted and number_of_courses_viewed with a value of 0.44\n"
     ]
    }
   ],
   "source": [
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# Find the pair with the largest correlation (excluding self-correlations)\n",
    "corr_unstacked = corr_matrix.unstack().sort_values(ascending=False)\n",
    "\n",
    "# Drop self-correlations (where correlation = 1)\n",
    "corr_unstacked = corr_unstacked[corr_unstacked < 1]\n",
    "\n",
    "# Get the top correlation pair\n",
    "biggest_corr = corr_unstacked.idxmax()\n",
    "corr_value = corr_unstacked.max()\n",
    "\n",
    "print(f\"The biggest correlation is between {biggest_corr[0]} and {biggest_corr[1]} with a value of {corr_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c1055dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_courses_viewed  number_of_courses_viewed    1.000000\n",
      "                          converted                   0.435914\n",
      "interaction_count         converted                   0.374573\n",
      "lead_score                converted                   0.193673\n",
      "annual_income             converted                   0.053131\n",
      "                          interaction_count           0.027036\n",
      "                          lead_score                  0.015610\n",
      "interaction_count         lead_score                  0.009888\n",
      "number_of_courses_viewed  annual_income               0.009770\n",
      "                          lead_score                 -0.004879\n",
      "                          interaction_count          -0.023565\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = df.corr(numeric_only=True)\n",
    "\n",
    "# Unstack (flatten) the matrix to get all pairs\n",
    "corr_pairs = corr_matrix.unstack()\n",
    "\n",
    "# Remove duplicate pairs and self-correlations (where correlation = 1)\n",
    "corr_pairs = corr_pairs.drop_duplicates().sort_values(ascending=False)\n",
    "\n",
    "# Display all correlation scores\n",
    "print(corr_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aae7f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96fe6459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Feature  MI Score\n",
      "2        lead_source  0.026574\n",
      "3  employment_status  0.011070\n",
      "0           industry  0.007267\n",
      "1           location  0.001427\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Select categorical features\n",
    "categorical_cols = ['industry', 'location', 'lead_source', 'employment_status']\n",
    "\n",
    "# Drop rows with missing values in these columns or in target\n",
    "data = df[categorical_cols + ['converted']].dropna()\n",
    "\n",
    "# Convert categorical columns to numeric codes\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].astype('category').cat.codes\n",
    "\n",
    "# Compute MI\n",
    "X = data[categorical_cols]\n",
    "y = data['converted']\n",
    "mi_scores = mutual_info_classif(X, y, discrete_features=True, random_state=1)\n",
    "\n",
    "# Create a table of MI results\n",
    "mi_df = pd.DataFrame({'Feature': categorical_cols, 'MI Score': mi_scores}).sort_values(by='MI Score', ascending=False)\n",
    "print(mi_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b188cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Select features (you can use the most relevant ones)\n",
    "features = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "X = df[features]\n",
    "y = df['converted']\n",
    "\n",
    "# Handle missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "# Train a model\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb12e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C: 10\n",
      "Best cross-validation accuracy: 0.8187152274533638\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Select numeric features only for simplicity\n",
    "X = df[['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']].fillna(0)\n",
    "y = df['converted']\n",
    "\n",
    "# Define pipeline: scaling + logistic regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'logreg__C': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(X, y)\n",
    "\n",
    "# Best parameter and score\n",
    "print(\"Best C:\", grid.best_params_['logreg__C'])\n",
    "print(\"Best cross-validation accuracy:\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71142480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01: Accuracy=0.71\n",
      "C=0.1: Accuracy=0.71\n",
      "C=1: Accuracy=0.71\n",
      "C=10: Accuracy=0.71\n",
      "C=100: Accuracy=0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use only one feature, for example\n",
    "X = df[['number_of_courses_viewed']].fillna(0)\n",
    "y = df['converted']\n",
    "\n",
    "# Simple train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Test each C\n",
    "for C in [0.01, 0.1, 1, 10, 100]:\n",
    "    model = LogisticRegression(C=C, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    acc = model.score(X_test, y_test)\n",
    "    print(f\"C={C}: Accuracy={acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
